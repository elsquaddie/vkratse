# üõ°Ô∏è SECURITY FIXES & BUG ROADMAP

> **–ü–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ—Ö —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –∏ –±–∞–≥–æ–≤**
> –ö–∞–∂–¥—ã–π —à–∞–≥: 1 –±–∞–≥ ‚Üí —Ñ–∏–∫—Å ‚Üí —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí ‚úÖ
> –°–æ–∑–¥–∞–Ω–æ: 2025-11-18

---

## üìñ –ö–ê–ö –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ –≠–¢–û–¢ –î–û–ö–£–ú–ï–ù–¢

### –§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã:
1. –û—Ç–∫—Ä–æ–π –Ω–æ–≤—ã–π —á–∞—Ç —Å Claude Code
2. –°–∫–∞–∂–∏: **"–î–µ–ª–∞–µ–º –®–ê–ì 1 –∏–∑ SECURITY_FIXES.md"**
3. Claude –ø—Ä–∏–º–µ–Ω–∏—Ç —Ñ–∏–∫—Å + —Å–æ–∑–¥–∞—Å—Ç —Ç–µ—Å—Ç
4. –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
5. –û—Ç–º–µ—Ç—å —á–µ–∫–±–æ–∫—Å ‚úÖ
6. –ü–µ—Ä–µ—Ö–æ–¥–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —à–∞–≥—É

### –ü–æ—Ä—è–¥–æ–∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
- **üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï (–®–∞–≥–∏ 1-10)** - –¥–µ–ª–∞–π –ü–ï–†–í–´–ú–ò, –Ω–µ –æ—Ç–∫–ª–∞–¥—ã–≤–∞—è
- **üü† –í–ê–ñ–ù–´–ï (–®–∞–≥–∏ 11-18)** - –¥–µ–ª–∞–π –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ–¥–µ–ª–∏
- **üü° –£–õ–£–ß–®–ï–ù–ò–Ø (–®–∞–≥–∏ 19+)** - –¥–µ–ª–∞–π –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≤—Ä–µ–º—è

### –ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º:
```bash
# –°–æ–∑–¥–∞–π –Ω–æ–≤—É—é –≤–µ—Ç–∫—É
git checkout -b security-fixes

# –£—Å—Ç–∞–Ω–æ–≤–∏ dev-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ)
pip install -r requirements-dev.txt
```

---

## üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ë–ê–ì–ò (–ù–ï–ú–ï–î–õ–ï–ù–ù–û!)

### –®–ê–ì 1: SQL Injection –≤ db_service.py

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** Data breach, –ø–æ–ª–Ω–∞—è –∫–æ–º–ø—Ä–æ–º–µ—Ç–∞—Ü–∏—è –ë–î
**–§–∞–π–ª—ã:** `services/db_service.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# services/db_service.py:516
.or_(f'user_id.eq.{user_id}')  # ‚ùå SQL INJECTION!
```

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ f-string –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è SQL-–∑–∞–ø—Ä–æ—Å–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç inject –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π SQL –∫–æ–¥.

**–ü—Ä–∏–º–µ—Ä –∞—Ç–∞–∫–∏:**
```python
user_id = "1; DROP TABLE messages; --"
# –†–µ–∑—É–ª—å—Ç–∞—Ç: .or_(f'user_id.eq.1; DROP TABLE messages; --')
```

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É 516 –≤ `services/db_service.py`:**
```python
# –ë–´–õ–û (–û–ü–ê–°–ù–û!):
.or_(f'user_id.eq.{user_id}')

# –°–¢–ê–õ–û (–ë–ï–ó–û–ü–ê–°–ù–û):
.or_(f"user_id.eq.{int(user_id)},user_id.is.null")
```

**2. –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—å –¥—Ä—É–≥–∏–µ –º–µ—Å—Ç–∞ —Å f-string –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ö:**
```bash
# –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º:
grep -n "f'" services/db_service.py | grep -E "(eq|neq|gt|lt|in)"
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/security/test_sql_injection.py`

```python
import pytest
from services.db_service import DBService

def test_sql_injection_protection():
    """Test that SQL injection is blocked"""
    db = DBService()

    # –ü–æ–ø—ã—Ç–∫–∞ SQL injection —á–µ—Ä–µ–∑ user_id
    malicious_user_id = "1; DROP TABLE messages; --"

    with pytest.raises((ValueError, TypeError)):
        # –î–æ–ª–∂–µ–Ω —É–ø–∞—Å—Ç—å —Å –æ—à–∏–±–∫–æ–π, —Ç.–∫. int() –Ω–µ –º–æ–∂–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å
        db.get_user_personalities(malicious_user_id)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ë–î –Ω–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∞
    result = db.client.table('messages').select('id').limit(1).execute()
    assert result is not None  # –¢–∞–±–ª–∏—Ü–∞ –Ω–µ —É–¥–∞–ª–µ–Ω–∞

def test_valid_user_id_works():
    """Test that valid user_id still works"""
    db = DBService()

    # –í–∞–ª–∏–¥–Ω—ã–π ID –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å
    result = db.get_user_personalities(123456789)
    assert isinstance(result, list)
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç
pytest tests/security/test_sql_injection.py -v

# –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
# ‚úÖ test_sql_injection_protection PASSED
# ‚úÖ test_valid_user_id_works PASSED
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] F-string –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –ù–µ—Ç –¥—Ä—É–≥–∏—Ö f-string –≤ SQL-—Ñ–∏–ª—å—Ç—Ä–∞—Ö
- [ ] –ö–æ–º–º–∏—Ç —Å–æ–∑–¥–∞–Ω: `git commit -m "fix: SQL injection in db_service.py"`

---

### –®–ê–ì 2: –î–µ—Ñ–æ–ª—Ç–Ω—ã–π SECRET_KEY –≤ –∫–æ–¥–µ

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** –í—Å–µ HMAC –ø–æ–¥–ø–∏—Å–∏ —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω—ã
**–§–∞–π–ª—ã:** `config.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# config.py:33
SECRET_KEY = os.getenv('SECRET_KEY', 'your-secret-key-change-in-production')
```

–ï—Å–ª–∏ `SECRET_KEY` –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ environment variables, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:
- –õ—é–±–æ–π –º–æ–∂–µ—Ç –ø–æ–¥–¥–µ–ª–∞—Ç—å HMAC –ø–æ–¥–ø–∏—Å–∏
- Callback_data –º–æ–∂–Ω–æ forge
- –ù–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø –∫ —Ñ—É–Ω–∫—Ü–∏—è–º –±–æ—Ç–∞

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ó–∞–º–µ–Ω–∏ —Å—Ç—Ä–æ–∫—É 33 –≤ `config.py`:**
```python
# –ë–´–õ–û (–û–ü–ê–°–ù–û!):
SECRET_KEY = os.getenv('SECRET_KEY', 'your-secret-key-change-in-production')

# –°–¢–ê–õ–û (–ë–ï–ó–û–ü–ê–°–ù–û):
SECRET_KEY = os.getenv('SECRET_KEY')
if not SECRET_KEY:
    raise ValueError(
        "‚ùå SECRET_KEY environment variable is required!\n"
        "Generate: python -c 'import secrets; print(secrets.token_hex(32))'\n"
        "Set in Vercel: Settings ‚Üí Environment Variables ‚Üí Add SECRET_KEY"
    )
```

**2. –î–æ–±–∞–≤—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤ validation:**
```python
# config.py - –≤ —Ñ—É–Ω–∫—Ü–∏–∏ validate_config() –¥–æ–±–∞–≤—å:
def validate_config():
    """Validate required configuration"""
    errors = []

    # ... existing checks ...

    # NEW: Check SECRET_KEY strength
    if len(SECRET_KEY) < 32:
        errors.append("SECRET_KEY must be at least 32 characters (use secrets.token_hex(32))")

    if errors:
        if os.getenv('ENV') == 'production':
            raise ValueError(f"Configuration errors:\n" + "\n".join(errors))
        else:
            logger.warning(f"Configuration warnings:\n" + "\n".join(errors))
```

**3. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –Ω–æ–≤—ã–π SECRET_KEY:**
```bash
# –õ–æ–∫–∞–ª—å–Ω–æ
python -c "import secrets; print(secrets.token_hex(32))"

# –£—Å—Ç–∞–Ω–æ–≤–∏ –≤ Vercel Dashboard:
# Settings ‚Üí Environment Variables ‚Üí Add:
# SECRET_KEY = <generated_value>
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/unit/test_config.py`

```python
import pytest
import os

def test_secret_key_required():
    """Test that SECRET_KEY is required"""
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π SECRET_KEY
    original = os.getenv('SECRET_KEY')

    # –£–±–∏—Ä–∞–µ–º SECRET_KEY
    if 'SECRET_KEY' in os.environ:
        del os.environ['SECRET_KEY']

    # –ò–º–ø–æ—Ä—Ç –¥–æ–ª–∂–µ–Ω —É–ø–∞—Å—Ç—å
    with pytest.raises(ValueError, match="SECRET_KEY environment variable is required"):
        import importlib
        import config
        importlib.reload(config)

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    if original:
        os.environ['SECRET_KEY'] = original

def test_secret_key_length():
    """Test that SECRET_KEY has sufficient length"""
    import config
    assert len(config.SECRET_KEY) >= 32, "SECRET_KEY must be at least 32 characters"

def test_secret_key_not_default():
    """Test that SECRET_KEY is not default value"""
    import config
    forbidden_values = [
        'your-secret-key-change-in-production',
        'secret',
        'password',
        '12345',
    ]
    assert config.SECRET_KEY not in forbidden_values, "SECRET_KEY is using default/weak value"
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/unit/test_config.py -v

# 2. –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ –±–µ–∑ SECRET_KEY –±–æ—Ç –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è
unset SECRET_KEY
python -c "import config"  # –î–æ–ª–∂–µ–Ω —É–ø–∞—Å—Ç—å —Å –æ—à–∏–±–∫–æ–π

# 3. –£—Å—Ç–∞–Ω–æ–≤–∏ SECRET_KEY –∏ –ø—Ä–æ–≤–µ—Ä—å —Å–Ω–æ–≤–∞
export SECRET_KEY=$(python -c 'import secrets; print(secrets.token_hex(32))')
python -c "import config; print('OK')"  # –î–æ–ª–∂–µ–Ω –≤—ã–≤–µ—Å—Ç–∏ OK
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–æ
- [ ] –ë–æ—Ç –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ SECRET_KEY
- [ ] SECRET_KEY >= 32 —Å–∏–º–≤–æ–ª–æ–≤
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –ù–æ–≤—ã–π SECRET_KEY —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ Vercel
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: require SECRET_KEY, remove default"`

---

### –®–ê–ì 3: Race Condition –≤ asyncio.all_tasks()

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** –ó–∞–≤–µ—Ä—à–∞–µ—Ç tasks –¥—Ä—É–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ serverless
**–§–∞–π–ª—ã:** `api/index.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# api/index.py:644-646
pending = asyncio.all_tasks(loop)
results = loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
```

`asyncio.all_tasks()` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç **–í–°–ï** tasks –≤ event loop, –≤–∫–ª—é—á–∞—è tasks –∏–∑ –¥—Ä—É–≥–∏—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Ç–æ–º –∂–µ Vercel worker. –≠—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫:
- –ó–∞–≤–µ—Ä—à–µ–Ω–∏—é —á—É–∂–∏—Ö tasks
- –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º –æ—à–∏–±–∫–∞–º
- Data corruption

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫–∏ 644-646 –≤ `api/index.py`:**
```python
# –ë–´–õ–û (–û–ü–ê–°–ù–û!):
pending = asyncio.all_tasks(loop)
results = loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

# –°–¢–ê–õ–û (–ë–ï–ó–û–ü–ê–°–ù–û):
current = asyncio.current_task(loop)
pending = [
    task for task in asyncio.all_tasks(loop)
    if not task.done() and task != current
]

if pending:
    results = loop.run_until_complete(
        asyncio.gather(*pending, return_exceptions=True, timeout=8.0)
    )

    # Log any exceptions
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            logger.error(f"Task {i} failed: {result}")
```

**2. –î–æ–±–∞–≤—å timeout –Ω–∞ process_update():**
```python
# api/index.py - –≤ —Ñ—É–Ω–∫—Ü–∏–∏ application(), –Ω–∞–π–¥–∏:
# loop.run_until_complete(process_update(update_data))

# –ó–∞–º–µ–Ω–∏ –Ω–∞:
try:
    loop.run_until_complete(
        asyncio.wait_for(process_update(update_data), timeout=8.0)
    )
except asyncio.TimeoutError:
    logger.error("Update processing timeout (>8s)")
    start_response('504 Gateway Timeout', headers)
    return [b'{"ok": false, "error": "timeout"}']
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/integration/test_concurrent_webhooks.py`

```python
import pytest
import asyncio
from unittest.mock import patch, MagicMock

@pytest.mark.asyncio
async def test_concurrent_webhooks_isolation():
    """Test that concurrent webhooks don't interfere"""
    from api.index import process_update

    # –°–∏–º—É–ª–∏—Ä—É–µ–º 2 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö webhook
    update1 = {'update_id': 1, 'message': {'text': '/start', 'chat': {'id': 1}}}
    update2 = {'update_id': 2, 'message': {'text': '/help', 'chat': {'id': 2}}}

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(
        process_update(update1),
        process_update(update2),
        return_exceptions=True
    )

    # –û–±–∞ –¥–æ–ª–∂–Ω—ã –∑–∞–≤–µ—Ä—à–∏—Ç—å—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
    assert not isinstance(results[0], Exception)
    assert not isinstance(results[1], Exception)

@pytest.mark.asyncio
async def test_task_cleanup_only_own_tasks():
    """Test that cleanup doesn't affect other tasks"""
    async def dummy_task():
        await asyncio.sleep(10)

    # –°–æ–∑–¥–∞—ë–º "—á—É–∂–æ–π" task
    other_task = asyncio.create_task(dummy_task())

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º cleanup –ª–æ–≥–∏–∫—É
    from api.index import application

    # ... simulate request processing ...

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —á—É–∂–æ–π task –ù–ï –±—ã–ª –æ—Ç–º–µ–Ω—ë–Ω
    assert not other_task.done(), "Other task was cancelled!"

    # Cleanup
    other_task.cancel()
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/integration/test_concurrent_webhooks.py -v

# Stress test (–µ—Å–ª–∏ –µ—Å—Ç—å staging):
# –û—Ç–ø—Ä–∞–≤—å 10 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö webhooks –∏ –ø—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è tasks –ø–æ current_task()
- [ ] –î–æ–±–∞–≤–ª–µ–Ω timeout 8 —Å–µ–∫—É–Ω–¥
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –ù–µ—Ç –æ—à–∏–±–æ–∫ –≤ –ª–æ–≥–∞—Ö –ø—Ä–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–∞—Ö
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: race condition in asyncio tasks cleanup"`

---

### –®–ê–ì 4: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Telegram Webhook Verification

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** –õ—é–±–æ–π –º–æ–∂–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç—å fake updates
**–§–∞–π–ª—ã:** `api/index.py`, `config.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
Telegram webhook –ø—Ä–∏–Ω–∏–º–∞–µ—Ç POST –∑–∞–ø—Ä–æ—Å—ã –æ—Ç –∫–æ–≥–æ —É–≥–æ–¥–Ω–æ. –ù–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ —á—Ç–æ –∑–∞–ø—Ä–æ—Å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ—Ç Telegram.

**–ü—Ä–∏–º–µ—Ä –∞—Ç–∞–∫–∏:**
```bash
# –ó–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫ –º–æ–∂–µ—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç—å:
curl -X POST https://vkratse.vercel.app/api/index \
  -H "Content-Type: application/json" \
  -d '{"update_id": 999, "message": {"text": "/admin", "from": {"id": 123}}}'

# –ë–æ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –Ω–∞—Å—Ç–æ—è—â–∏–π update!
```

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –î–æ–±–∞–≤—å –≤ `config.py`:**
```python
# config.py - –ø–æ—Å–ª–µ SECRET_KEY
TELEGRAM_WEBHOOK_SECRET = os.getenv('TELEGRAM_WEBHOOK_SECRET')
if not TELEGRAM_WEBHOOK_SECRET:
    raise ValueError(
        "‚ùå TELEGRAM_WEBHOOK_SECRET environment variable is required!\n"
        "Generate: python -c 'import secrets; print(secrets.token_urlsafe(32))'\n"
        "Set webhook: curl 'https://api.telegram.org/bot<TOKEN>/setWebhook?"
        "url=https://vkratse.vercel.app&secret_token=<SECRET>'"
    )
```

**2. –î–æ–±–∞–≤—å –ø—Ä–æ–≤–µ—Ä–∫—É –≤ `api/index.py`:**
```python
# api/index.py - –≤ –Ω–∞—á–∞–ª–µ —Ñ—É–Ω–∫—Ü–∏–∏ application(), –ü–ï–†–ï–î content_length:

def application(environ, start_response):
    """WSGI application entry point"""

    # ===== NEW: WEBHOOK VERIFICATION =====
    webhook_secret = environ.get('HTTP_X_TELEGRAM_BOT_API_SECRET_TOKEN')

    if webhook_secret != config.TELEGRAM_WEBHOOK_SECRET:
        logger.warning(
            f"‚ùå Webhook verification failed! "
            f"IP: {environ.get('REMOTE_ADDR')}, "
            f"Secret: {webhook_secret[:10]}... (expected {config.TELEGRAM_WEBHOOK_SECRET[:10]}...)"
        )
        start_response('403 Forbidden', [('Content-Type', 'application/json')])
        return [b'{"ok": false, "error": "forbidden"}']
    # ===== END VERIFICATION =====

    # ... rest of existing code ...
```

**3. –£—Å—Ç–∞–Ω–æ–≤–∏ secret –≤ Telegram:**
```bash
# 1. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π secret
SECRET=$(python -c 'import secrets; print(secrets.token_urlsafe(32))')
echo "Generated secret: $SECRET"

# 2. –£—Å—Ç–∞–Ω–æ–≤–∏ –≤ Vercel
# Vercel Dashboard ‚Üí Settings ‚Üí Environment Variables ‚Üí Add:
# TELEGRAM_WEBHOOK_SECRET = <secret>

# 3. –û–±–Ω–æ–≤–∏ webhook –≤ Telegram
curl "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/setWebhook?url=https://vkratse.vercel.app&secret_token=${SECRET}"

# 4. –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ webhook —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
curl "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/getWebhookInfo"
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/security/test_webhook_verification.py`

```python
import pytest
from unittest.mock import Mock
from api.index import application

def test_webhook_without_secret_rejected():
    """Test that webhook without secret is rejected"""
    environ = {
        'REQUEST_METHOD': 'POST',
        'CONTENT_LENGTH': '100',
        'wsgi.input': Mock(),
        # NO HTTP_X_TELEGRAM_BOT_API_SECRET_TOKEN header
    }

    responses = []
    def start_response(status, headers):
        responses.append(status)

    result = application(environ, start_response)

    assert responses[0] == '403 Forbidden'
    assert b'forbidden' in b''.join(result)

def test_webhook_with_wrong_secret_rejected():
    """Test that webhook with wrong secret is rejected"""
    environ = {
        'REQUEST_METHOD': 'POST',
        'CONTENT_LENGTH': '100',
        'wsgi.input': Mock(),
        'HTTP_X_TELEGRAM_BOT_API_SECRET_TOKEN': 'WRONG_SECRET',
    }

    responses = []
    def start_response(status, headers):
        responses.append(status)

    result = application(environ, start_response)

    assert responses[0] == '403 Forbidden'

def test_webhook_with_correct_secret_accepted():
    """Test that webhook with correct secret is accepted"""
    import config

    environ = {
        'REQUEST_METHOD': 'POST',
        'CONTENT_LENGTH': '50',
        'wsgi.input': Mock(read=lambda: b'{"update_id": 1, "message": {}}'),
        'HTTP_X_TELEGRAM_BOT_API_SECRET_TOKEN': config.TELEGRAM_WEBHOOK_SECRET,
    }

    responses = []
    def start_response(status, headers):
        responses.append(status)

    result = application(environ, start_response)

    # –ù–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 403
    assert '403' not in responses[0]
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/security/test_webhook_verification.py -v

# 2. –ü–æ–ø—Ä–æ–±—É–π fake webhook (–¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å 403)
curl -X POST https://vkratse.vercel.app/api/index \
  -H "Content-Type: application/json" \
  -d '{"update_id": 999}'

# 3. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ Vercel - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø–∏—Å—å "Webhook verification failed"
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] TELEGRAM_WEBHOOK_SECRET –¥–æ–±–∞–≤–ª–µ–Ω –≤ config
- [ ] –ü—Ä–æ–≤–µ—Ä–∫–∞ secret –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ application()
- [ ] Secret —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ Vercel
- [ ] Webhook –æ–±–Ω–æ–≤–ª—ë–Ω –≤ Telegram
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Fake webhooks –æ—Ç–∫–ª–æ–Ω—è—é—Ç—Å—è (403)
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: add Telegram webhook verification"`

---

### –®–ê–ì 5: –ë–ê–ì –≤ Cache TTL (.seconds)

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** Cache –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –¥–Ω–∏/—á–∞—Å—ã, —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ
**–§–∞–π–ª—ã:** `services/subscription.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# services/subscription.py:318
if (datetime.now(timezone.utc) - checked_at).seconds < 3600:
```

`.seconds` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç **—Ç–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥—ã –≤–Ω—É—Ç—Ä–∏ –º–∏–Ω—É—Ç—ã** (0-59), –∏–≥–Ω–æ—Ä–∏—Ä—É—è –¥–Ω–∏ –∏ —á–∞—Å—ã!

**–ü—Ä–∏–º–µ—Ä –±–∞–≥–∞:**
```python
from datetime import datetime, timedelta

# –†–∞–∑–Ω–∏—Ü–∞: 2 –¥–Ω—è 1 —á–∞—Å 30 —Å–µ–∫—É–Ω–¥
delta = timedelta(days=2, hours=1, seconds=30)

print(delta.seconds)         # –í—ã–≤–æ–¥: 3630 (—Ç–æ–ª—å–∫–æ 1 —á–∞—Å 30 —Å–µ–∫, –ë–ï–ó 2 –¥–Ω–µ–π!)
print(delta.total_seconds()) # –í—ã–≤–æ–¥: 176430 (–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –≤—Å—ë –≤–∫–ª—é—á–µ–Ω–æ)

# –†–µ–∑—É–ª—å—Ç–∞—Ç: cache TTL –ø—Ä–æ–≤–µ—Ä–∫–∞ –ù–ï–í–ï–†–ù–ê!
```

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ù–∞–π–¥–∏ —Å—Ç—Ä–æ–∫—É 318 –≤ `services/subscription.py`:**
```python
# –ë–´–õ–û (–ë–ê–ì!):
if (datetime.now(timezone.utc) - checked_at).seconds < 3600:
    return self._cache[user_id]

# –°–¢–ê–õ–û (–ü–†–ê–í–ò–õ–¨–ù–û):
if (datetime.now(timezone.utc) - checked_at).total_seconds() < 3600:
    return self._cache[user_id]
```

**2. –ü—Ä–æ–≤–µ—Ä—å –¥—Ä—É–≥–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è `.seconds`:**
```bash
# –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
grep -n "\.seconds" services/*.py modules/*.py

# –ó–∞–º–µ–Ω–∏ –í–°–ï .seconds –Ω–∞ .total_seconds() –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è TTL/timeout
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/unit/test_cache_ttl.py`

```python
import pytest
from datetime import datetime, timedelta, timezone
from services.subscription import SubscriptionService
from unittest.mock import Mock

def test_cache_ttl_respects_hours_and_days():
    """Test that cache TTL correctly handles hours and days"""
    db_mock = Mock()
    service = SubscriptionService(db_mock)

    # –î–æ–±–∞–≤–∏–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ cache
    user_id = 123456789
    test_tier = 'pro'

    # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å—Ç–∞—Ä—ã–π cache (2 —á–∞—Å–∞ –Ω–∞–∑–∞–¥)
    old_time = datetime.now(timezone.utc) - timedelta(hours=2)
    service._cache[user_id] = test_tier
    service._cache_time[user_id] = old_time

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∫—É
    result = service._get_cached_subscription(user_id)

    # Cache –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ù–ï–í–ê–õ–ò–î–ï–ù (>1 —á–∞—Å), –ø–æ—ç—Ç–æ–º—É result –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å None
    assert result is None, "Cache should be invalid after 2 hours!"

def test_cache_ttl_works_within_hour():
    """Test that cache is valid within 1 hour"""
    db_mock = Mock()
    service = SubscriptionService(db_mock)

    user_id = 123456789
    test_tier = 'premium'

    # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–≤–µ–∂–∏–π cache (30 –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥)
    recent_time = datetime.now(timezone.utc) - timedelta(minutes=30)
    service._cache[user_id] = test_tier
    service._cache_time[user_id] = recent_time

    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∫—É
    result = service._get_cached_subscription(user_id)

    # Cache –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –í–ê–õ–ò–î–ï–ù (<1 —á–∞—Å)
    assert result == test_tier, "Cache should be valid within 1 hour!"

def test_timedelta_seconds_vs_total_seconds():
    """Demonstrate the bug with .seconds vs .total_seconds()"""
    # 2 –¥–Ω—è 1 —á–∞—Å 30 —Å–µ–∫—É–Ω–¥
    delta = timedelta(days=2, hours=1, seconds=30)

    # .seconds –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –¥–Ω–∏)
    assert delta.seconds == 3630  # –¢–æ–ª—å–∫–æ 1 —á–∞—Å 30 —Å–µ–∫

    # .total_seconds() –ü–†–ê–í–ò–õ–¨–ù–û (–≤—Å—ë –≤–∫–ª—é—á–µ–Ω–æ)
    assert delta.total_seconds() == 176430  # 2 –¥–Ω—è + 1 —á–∞—Å + 30 —Å–µ–∫

    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–≥–∞:
    # –ï—Å–ª–∏ checked_at –±—ã–ª 2 –¥–Ω—è –Ω–∞–∑–∞–¥, –Ω–æ .seconds < 3600 (1 —á–∞—Å):
    # –°—Ç–∞—Ä—ã–π –∫–æ–¥ —Å—á–∏—Ç–∞–ª –±—ã cache –≤–∞–ª–∏–¥–Ω—ã–º! ‚ùå
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/unit/test_cache_ttl.py -v

# –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
# ‚úÖ test_cache_ttl_respects_hours_and_days PASSED
# ‚úÖ test_cache_ttl_works_within_hour PASSED
# ‚úÖ test_timedelta_seconds_vs_total_seconds PASSED
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] `.seconds` –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ `.total_seconds()`
- [ ] –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –ù–µ—Ç –¥—Ä—É–≥–∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π `.seconds` –¥–ª—è TTL
- [ ] Cache —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: cache TTL bug - use total_seconds()"`

---

### –®–ê–ì 6: YooKassa Handler –Ω–µ Async

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** –ü–ª–∞—Ç–µ–∂–∏ –ù–ï –û–ë–†–ê–ë–ê–¢–´–í–ê–Æ–¢–°–Ø
**–§–∞–π–ª—ã:** `api/yookassa_webhook.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# api/yookassa_webhook.py:67
def handler(request):  # ‚ùå Sync —Ñ—É–Ω–∫—Ü–∏—è
    # ...
    loop.run_until_complete(process_payment(...))  # ‚ùå –í—ã–∑—ã–≤–∞–µ—Ç async
```

Vercel Python runtime –æ–∂–∏–¥–∞–µ—Ç:
- **Sync** handler –¥–ª—è WSGI
- **Async** handler –¥–ª—è ASGI

–¢–µ–∫—É—â–∏–π –∫–æ–¥ - hybrid (sync –≤—ã–∑—ã–≤–∞–µ—Ç async) - **–ù–ï –†–ê–ë–û–¢–ê–ï–¢ –ö–û–†–†–ï–ö–¢–ù–û** –≤ serverless.

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ó–∞–º–µ–Ω–∏ –≤—Å—é —Ñ—É–Ω–∫—Ü–∏—é `handler()` –≤ `api/yookassa_webhook.py`:**

```python
# api/yookassa_webhook.py:67-142

# –ë–´–õ–û (–ù–ï –†–ê–ë–û–¢–ê–ï–¢):
def handler(request):
    """
    Vercel serverless function handler for YooKassa webhooks
    """
    # ... sync –∫–æ–¥ ...
    loop.run_until_complete(process_payment(...))

# –°–¢–ê–õ–û (–†–ê–ë–û–¢–ê–ï–¢):
async def handler(request):
    """
    Vercel serverless function handler for YooKassa webhooks
    """
    if request.method != 'POST':
        return {
            'statusCode': 405,
            'body': json.dumps({'error': 'Method not allowed'})
        }

    # Get request body
    try:
        body = await request.body() if hasattr(request, 'body') else request.get_json()
    except Exception as e:
        logger.error(f"Failed to parse request body: {e}")
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'Invalid request body'})
        }

    # Verify IP (–µ—Å–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞)
    client_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    if not verify_ip(client_ip):
        logger.warning(f"Webhook from unauthorized IP: {client_ip}")
        return {
            'statusCode': 403,
            'body': json.dumps({'error': 'Forbidden'})
        }

    # Process payment
    try:
        await process_payment(body)
        return {
            'statusCode': 200,
            'body': json.dumps({'status': 'ok'})
        }
    except Exception as e:
        logger.error(f"Payment processing failed: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({'error': 'Internal server error'})
        }
```

**2. –û–±–Ω–æ–≤–∏ export –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞:**
```python
# api/yookassa_webhook.py - –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞

# –ë–´–õ–û:
# def application(environ, start_response):
#     loop = asyncio.new_event_loop()
#     ...

# –°–¢–ê–õ–û:
def application(environ, start_response):
    """WSGI wrapper for async handler"""
    # –î–ª—è Vercel serverless –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä—è–º–æ–π async
    # –ù–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω WSGI, –∏—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç wrapper:

    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    try:
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º WSGI environ –≤ request-like –æ–±—ä–µ–∫—Ç
        from werkzeug.wrappers import Request
        request = Request(environ)

        # –í—ã–∑—ã–≤–∞–µ–º async handler
        result = loop.run_until_complete(handler(request))

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        status = f"{result['statusCode']} OK"
        headers = [('Content-Type', 'application/json')]
        start_response(status, headers)
        return [result['body'].encode()]

    except Exception as e:
        logger.error(f"Webhook error: {e}", exc_info=True)
        start_response('500 Internal Server Error', [])
        return [b'{"error": "internal error"}']
    finally:
        loop.close()
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/integration/test_yookassa_webhook.py`

```python
import pytest
import json
from unittest.mock import Mock, patch, AsyncMock

@pytest.mark.asyncio
async def test_yookassa_webhook_success():
    """Test successful payment webhook processing"""
    from api.yookassa_webhook import handler

    # Mock request
    request = Mock()
    request.method = 'POST'
    request.headers = {'X-Forwarded-For': '185.71.76.0'}  # YooKassa IP

    payment_data = {
        'event': 'payment.succeeded',
        'object': {
            'id': 'test-payment-id',
            'metadata': {'user_id': '123456789', 'tier': 'pro'},
            'status': 'succeeded'
        }
    }
    request.body = AsyncMock(return_value=json.dumps(payment_data))
    request.get_json = Mock(return_value=payment_data)

    # Mock DB
    with patch('services.db_service.DBService') as mock_db:
        mock_db.return_value.create_subscription = AsyncMock()

        # Call handler
        result = await handler(request)

        assert result['statusCode'] == 200
        assert 'ok' in result['body']

@pytest.mark.asyncio
async def test_yookassa_webhook_invalid_method():
    """Test that non-POST requests are rejected"""
    from api.yookassa_webhook import handler

    request = Mock()
    request.method = 'GET'

    result = await handler(request)

    assert result['statusCode'] == 405
    assert 'not allowed' in result['body'].lower()

@pytest.mark.asyncio
async def test_yookassa_webhook_malformed_body():
    """Test that malformed requests return 400"""
    from api.yookassa_webhook import handler

    request = Mock()
    request.method = 'POST'
    request.body = AsyncMock(side_effect=Exception("Parse error"))
    request.get_json = Mock(side_effect=Exception("Parse error"))

    result = await handler(request)

    assert result['statusCode'] == 400
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/integration/test_yookassa_webhook.py -v

# 2. –û—Ç–ø—Ä–∞–≤—å —Ç–µ—Å—Ç–æ–≤—ã–π webhook (–∏—Å–ø–æ–ª—å–∑—É–π YooKassa test mode)
curl -X POST https://vkratse.vercel.app/api/yookassa_webhook \
  -H "Content-Type: application/json" \
  -d '{
    "event": "payment.succeeded",
    "object": {
      "id": "test-123",
      "metadata": {"user_id": "123", "tier": "pro"},
      "status": "succeeded"
    }
  }'

# 3. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ Vercel - –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—à–∏–±–æ–∫ event loop
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] `handler()` —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ–ø–µ—Ä—å async
- [ ] WSGI wrapper –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—ã–∑—ã–≤–∞–µ—Ç async handler
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –¢–µ—Å—Ç–æ–≤—ã–π webhook –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- [ ] –í –ª–æ–≥–∞—Ö –Ω–µ—Ç "event loop" errors
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: make YooKassa handler async"`

---

### –®–ê–ì 7: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Idempotency Check

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** Duplicate webhooks ‚Üí –¥–≤–æ–π–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
**–§–∞–π–ª—ã:** `api/index.py`, `api/yookassa_webhook.py`, SQL migration

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
Telegram –∏ YooKassa –º–æ–≥—É—Ç –æ—Ç–ø—Ä–∞–≤–∏—Ç—å duplicate webhooks –ø—Ä–∏:
- Network timeouts
- Retry logic
- Infrastructure issues

–ë–µ–∑ idempotency check:
- Telegram update –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –¥–≤–∞–∂–¥—ã (–¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ë–î)
- –ü–ª–∞—Ç—ë–∂ –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è –¥–≤–∞–∂–¥—ã (–¥–≤–æ–π–Ω–∞—è –ø–æ–¥–ø–∏—Å–∫–∞)

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –°–æ–∑–¥–∞–π SQL –º–∏–≥—Ä–∞—Ü–∏—é:** `sql/migrations/005_webhook_log.sql`

```sql
-- –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è idempotency check
CREATE TABLE IF NOT EXISTS webhook_log (
    id BIGSERIAL PRIMARY KEY,
    webhook_type VARCHAR(50) NOT NULL, -- 'telegram' –∏–ª–∏ 'yookassa'
    webhook_id VARCHAR(255) NOT NULL,  -- update_id –∏–ª–∏ payment_id
    processed_at TIMESTAMP DEFAULT NOW(),
    payload JSONB,                     -- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏

    UNIQUE(webhook_type, webhook_id)
);

-- –ò–Ω–¥–µ–∫—Å—ã
CREATE INDEX idx_webhook_log_type_id ON webhook_log(webhook_type, webhook_id);
CREATE INDEX idx_webhook_log_processed ON webhook_log(processed_at);

-- Auto-cleanup —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (>7 –¥–Ω–µ–π)
-- –ó–∞–ø—É—Å–∫–∞—Ç—å —á–µ—Ä–µ–∑ cron –∏–ª–∏ manual cleanup script
```

**2. –î–æ–±–∞–≤—å –º–µ—Ç–æ–¥ –≤ `services/db_service.py`:**

```python
# services/db_service.py - –¥–æ–±–∞–≤—å –≤ –∫–ª–∞—Å—Å DBService

def check_and_mark_webhook_processed(
    self,
    webhook_type: str,
    webhook_id: str,
    payload: dict = None
) -> bool:
    """
    Check if webhook was already processed, and mark as processed if not.

    Returns:
        True if webhook is NEW (should be processed)
        False if webhook was already processed (skip)
    """
    try:
        # Check if exists
        result = self.client.table('webhook_log')\
            .select('webhook_id')\
            .eq('webhook_type', webhook_type)\
            .eq('webhook_id', str(webhook_id))\
            .execute()

        if result.data:
            logger.warning(
                f"Duplicate {webhook_type} webhook: {webhook_id}, skipping"
            )
            return False  # Already processed

        # Mark as processed
        self.client.table('webhook_log').insert({
            'webhook_type': webhook_type,
            'webhook_id': str(webhook_id),
            'payload': payload  # Optional
        }).execute()

        return True  # New webhook, should process

    except Exception as e:
        logger.error(f"Idempotency check failed: {e}")
        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ë–î - –ª—É—á—à–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å (—Ä–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–∞)
        return True
```

**3. –ò—Å–ø–æ–ª—å–∑—É–π –≤ `api/index.py`:**

```python
# api/index.py - –≤ —Ñ—É–Ω–∫—Ü–∏–∏ process_update(), –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ:

async def process_update(update_data: dict):
    """Process a single Telegram update"""
    update_id = update_data.get('update_id')

    # ===== NEW: IDEMPOTENCY CHECK =====
    db = DBService()
    if not db.check_and_mark_webhook_processed('telegram', update_id, update_data):
        logger.info(f"Skipping duplicate update {update_id}")
        return  # Already processed
    # ===== END IDEMPOTENCY CHECK =====

    # ... rest of existing code ...
```

**4. –ò—Å–ø–æ–ª—å–∑—É–π –≤ `api/yookassa_webhook.py`:**

```python
# api/yookassa_webhook.py - –≤ —Ñ—É–Ω–∫—Ü–∏–∏ process_payment():

async def process_payment(payment_data: dict):
    """Process YooKassa payment notification"""
    payment_id = payment_data['object']['id']

    # ===== NEW: IDEMPOTENCY CHECK =====
    db = DBService()
    if not db.check_and_mark_webhook_processed('yookassa', payment_id, payment_data):
        logger.info(f"Skipping duplicate payment {payment_id}")
        return  # Already processed
    # ===== END IDEMPOTENCY CHECK =====

    # ... rest of existing code ...
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/integration/test_idempotency.py`

```python
import pytest
from services.db_service import DBService

def test_first_webhook_is_processed():
    """Test that first webhook is marked for processing"""
    db = DBService()

    should_process = db.check_and_mark_webhook_processed(
        'telegram',
        'test_update_123'
    )

    assert should_process is True, "First webhook should be processed"

def test_duplicate_webhook_is_skipped():
    """Test that duplicate webhook is skipped"""
    db = DBService()
    webhook_id = 'test_update_456'

    # –ü–µ—Ä–≤—ã–π —Ä–∞–∑
    first = db.check_and_mark_webhook_processed('telegram', webhook_id)
    assert first is True

    # –í—Ç–æ—Ä–æ–π —Ä–∞–∑ (duplicate)
    second = db.check_and_mark_webhook_processed('telegram', webhook_id)
    assert second is False, "Duplicate webhook should be skipped"

def test_different_webhook_types_independent():
    """Test that same ID for different types are independent"""
    db = DBService()
    webhook_id = 'same_id_789'

    # Telegram webhook
    telegram = db.check_and_mark_webhook_processed('telegram', webhook_id)
    assert telegram is True

    # YooKassa webhook (same ID, but different type)
    yookassa = db.check_and_mark_webhook_processed('yookassa', webhook_id)
    assert yookassa is True, "Different types should be independent"

@pytest.mark.asyncio
async def test_telegram_duplicate_update_skipped():
    """Integration test: duplicate Telegram update is skipped"""
    from api.index import process_update

    update = {
        'update_id': 999888,
        'message': {
            'text': '/start',
            'chat': {'id': 123},
            'from': {'id': 456}
        }
    }

    # First processing
    await process_update(update)

    # Get messages count
    db = DBService()
    messages1 = db.client.table('messages').select('*').eq('chat_id', 123).execute()
    count1 = len(messages1.data)

    # Second processing (duplicate)
    await process_update(update)

    # Get messages count again
    messages2 = db.client.table('messages').select('*').eq('chat_id', 123).execute()
    count2 = len(messages2.data)

    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –û–î–ò–ù–ê–ö–û–í–û–ï –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (duplicate –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω)
    assert count1 == count2, "Duplicate update should not create duplicate messages"
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ü—Ä–∏–º–µ–Ω–∏ –º–∏–≥—Ä–∞—Ü–∏—é
psql $SUPABASE_URL -f sql/migrations/005_webhook_log.sql

# –ò–ª–∏ —á–µ—Ä–µ–∑ Supabase Dashboard:
# SQL Editor ‚Üí New Query ‚Üí –≤—Å—Ç–∞–≤—å SQL ‚Üí Run

# 2. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/integration/test_idempotency.py -v

# 3. –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–∑–¥–∞–Ω–∞
# Supabase Dashboard ‚Üí Table Editor ‚Üí webhook_log

# 4. –û—Ç–ø—Ä–∞–≤—å duplicate webhook –≤—Ä—É—á–Ω—É—é (–¥–≤–∞–∂–¥—ã –ø–æ–¥—Ä—è–¥):
curl -X POST https://vkratse.vercel.app/api/index \
  -H "X-Telegram-Bot-Api-Secret-Token: $TELEGRAM_WEBHOOK_SECRET" \
  -H "Content-Type: application/json" \
  -d '{"update_id": 777, "message": {"text": "test"}}'

# –í—Ç–æ—Ä–æ–π —Ä–∞–∑ —Å —Ç–µ–º –∂–µ update_id
curl -X POST https://vkratse.vercel.app/api/index \
  -H "X-Telegram-Bot-Api-Secret-Token: $TELEGRAM_WEBHOOK_SECRET" \
  -H "Content-Type: application/json" \
  -d '{"update_id": 777, "message": {"text": "test"}}'

# 5. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ - –≤—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –≤—ã–≤–µ—Å—Ç–∏ "Skipping duplicate"
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] –¢–∞–±–ª–∏—Ü–∞ `webhook_log` —Å–æ–∑–¥–∞–Ω–∞
- [ ] –ú–µ—Ç–æ–¥ `check_and_mark_webhook_processed()` –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] Idempotency check –≤ `api/index.py`
- [ ] Idempotency check –≤ `api/yookassa_webhook.py`
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Duplicate webhooks –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: add idempotency check for webhooks"`

---

### –®–ê–ì 8: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ HMAC Signatures

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** –£—Ç–µ—á–∫–∞ signatures ‚Üí –ø–æ–¥–¥–µ–ª–∫–∞ –ø–æ–¥–ø–∏—Å–µ–π
**–§–∞–π–ª—ã:** `utils/security.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# utils/security.py:73, 100
logger.info(f"[SIGNATURE CREATE] ... signature='{signature}'")
logger.debug(f"Expected signature: {expected_sig}")
```

Signatures –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ production logs. –ï—Å–ª–∏ –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫ –ø–æ–ª—É—á–∏—Ç –¥–æ—Å—Ç—É–ø –∫ –ª–æ–≥–∞–º:
- –ú–æ–∂–µ—Ç –ø–æ–¥–¥–µ–ª–∞—Ç—å –ª—é–±—ã–µ callback_data
- –û–±–æ–π—Ç–∏ HMAC –∑–∞—â–∏—Ç—É
- –ü–æ–ª—É—á–∏—Ç—å –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ù–∞–π–¥–∏ –∏ —É–¥–∞–ª–∏/–∑–∞–º–µ–Ω–∏ –≤—Å–µ –ª–æ–≥–∏ signatures –≤ `utils/security.py`:**

**–°—Ç—Ä–æ–∫–∞ 73:**
```python
# –ë–´–õ–û (–û–ü–ê–°–ù–û!):
logger.info(
    f"[SIGNATURE CREATE] user_id={user_id}, "
    f"data='{data}', signature='{signature}'"
)

# –°–¢–ê–õ–û (–ë–ï–ó–û–ü–ê–°–ù–û):
if config.DEBUG_MODE:  # –¢–æ–ª—å–∫–æ –≤ debug mode
    logger.debug(
        f"[SIGNATURE CREATE] user_id={user_id}, "
        f"data='{data}', signature='***REDACTED***'"
    )
else:
    logger.info(f"[SIGNATURE CREATE] user_id={user_id}, data_length={len(data)}")
```

**–°—Ç—Ä–æ–∫–∞ 100:**
```python
# –ë–´–õ–û (–û–ü–ê–°–ù–û!):
logger.debug(f"Expected signature: {expected_sig}")
logger.debug(f"Provided signature: {provided_signature}")

# –°–¢–ê–õ–û (–ë–ï–ó–û–ü–ê–°–ù–û):
if config.DEBUG_MODE:
    logger.debug(f"Expected signature: {expected_sig[:8]}...")
    logger.debug(f"Provided signature: {provided_signature[:8]}...")
else:
    logger.info("Signature verification in progress")
```

**–°—Ç—Ä–æ–∫–∞ 173 (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–æ—Ö–æ–∂–∏–µ –ª–æ–≥–∏):**
```python
# –í–µ–∑–¥–µ –≥–¥–µ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è signature/secret_key:
# –ë–´–õ–û: logger.info(f"... signature={sig}")
# –°–¢–ê–õ–û: logger.info(f"... signature={'***' if not config.DEBUG_MODE else sig[:8]+'...'}")
```

**2. –î–æ–±–∞–≤—å –≤ `config.py` —Ñ–ª–∞–≥ DEBUG_MODE:**
```python
# config.py - –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞
DEBUG_MODE = os.getenv('DEBUG_MODE', 'false').lower() == 'true'

# WARNING: Never enable DEBUG_MODE in production!
if DEBUG_MODE and os.getenv('ENV') == 'production':
    logger.warning("‚ö†Ô∏è DEBUG_MODE is enabled in production! Secrets may be logged!")
```

**3. –ü—Ä–æ–≤–µ—Ä—å –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã –Ω–∞ —É—Ç–µ—á–∫–∏:**
```bash
# –ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —É—Ç–µ—á–µ–∫
grep -rn "logger\." . --include="*.py" | grep -E "(signature|secret|token|password)" | grep -v "test"

# –ó–∞–º–µ–Ω–∏ –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –Ω–∞ redacted –≤–µ—Ä—Å–∏–∏
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/security/test_no_secret_leaks.py`

```python
import pytest
import logging
from io import StringIO
from utils.security import create_string_signature, verify_string_signature
import config

def test_signatures_not_logged_in_production(caplog):
    """Test that signatures are not logged in production mode"""
    # –°–∏–º—É–ª–∏—Ä—É–µ–º production mode
    original_debug = config.DEBUG_MODE
    config.DEBUG_MODE = False

    with caplog.at_level(logging.INFO):
        signature = create_string_signature("test_data", 12345)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ signature –ù–ï –≤ –ª–æ–≥–∞—Ö
    for record in caplog.records:
        assert signature not in record.message, \
            f"Signature leaked in log: {record.message}"
        assert "***" in record.message or "REDACTED" in record.message or \
               "data_length" in record.message, \
            "Log should contain redacted placeholder"

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    config.DEBUG_MODE = original_debug

def test_signatures_logged_in_debug_mode(caplog):
    """Test that signatures CAN be logged in debug mode (for development)"""
    # –°–∏–º—É–ª–∏—Ä—É–µ–º debug mode
    original_debug = config.DEBUG_MODE
    config.DEBUG_MODE = True

    with caplog.at_level(logging.DEBUG):
        signature = create_string_signature("test_data", 12345)

    # –í debug mode –º–æ–∂–Ω–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å (–Ω–æ —á–∞—Å—Ç–∏—á–Ω–æ)
    logged = any(sig[:8] in record.message for record in caplog.records for sig in [signature])
    # –ù–û –ø–æ–ª–Ω—ã–π signature –≤—Å—ë —Ä–∞–≤–Ω–æ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å
    full_logged = any(signature in record.message for record in caplog.records)

    assert not full_logged, "Full signature should never be logged!"

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
    config.DEBUG_MODE = original_debug

def test_secret_key_never_logged():
    """Test that SECRET_KEY is never logged"""
    import config
    import sys
    from io import StringIO

    # Capture all logs
    log_capture = StringIO()
    handler = logging.StreamHandler(log_capture)
    logging.root.addHandler(handler)

    # Do some operations that might log
    create_string_signature("test", 123)
    verify_string_signature("test", 123, "fake_sig")

    # Check logs
    logs = log_capture.getvalue()

    # SECRET_KEY –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –ª–æ–≥–∞—Ö –Ω–∏ –≤ –∫–∞–∫–æ–º –≤–∏–¥–µ
    assert config.SECRET_KEY not in logs, "SECRET_KEY leaked in logs!"

    # Cleanup
    logging.root.removeHandler(handler)
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/security/test_no_secret_leaks.py -v

# 2. –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ –≤ production –ª–æ–≥–∞—Ö –Ω–µ—Ç secrets
# Vercel Dashboard ‚Üí Logs ‚Üí Search –¥–ª—è "signature"

# 3. Grep –ø–æ –∫–æ–¥—É –Ω–∞ —É—Ç–µ—á–∫–∏
grep -rn "logger\." --include="*.py" | grep -E "(signature|secret)" | less

# 4. –£–±–µ–¥–∏—Å—å —á—Ç–æ DEBUG_MODE = false –≤ production
# Vercel Dashboard ‚Üí Environment Variables ‚Üí DEBUG_MODE –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å unset –∏–ª–∏ false
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] –í—Å–µ –ª–æ–≥–∏ signatures —É–¥–∞–ª–µ–Ω—ã –∏–ª–∏ redacted
- [ ] DEBUG_MODE —Ñ–ª–∞–≥ –¥–æ–±–∞–≤–ª–µ–Ω –≤ config
- [ ] –í production mode signatures –Ω–µ –ª–æ–≥–∏—Ä—É—é—Ç—Å—è
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Grep –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç —É—Ç–µ—á–µ–∫
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: remove signature logging, prevent secret leaks"`

---

### –®–ê–ì 9: –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ Retry –Ω–∞ DB Failures

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** Data loss –ø—Ä–∏ transient failures
**–§–∞–π–ª—ã:** `services/db_service.py`, `services/ai_service.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
–ù–µ—Ç retry –ª–æ–≥–∏–∫–∏ –¥–ª—è:
- Supabase API calls (network timeouts, rate limits)
- Claude API calls (429 errors, timeouts)

–û–¥–∏–Ω network glitch = failed request = –ø–æ—Ç–µ—Ä—è –¥–∞–Ω–Ω—ã—Ö.

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –î–æ–±–∞–≤—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –≤ `requirements.txt`:**
```
tenacity==8.2.3
```

**2. –°–æ–∑–¥–∞–π retry –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä—ã –≤ `utils/retry.py`:**

```python
# utils/retry.py - –ù–û–í–´–ô –§–ê–ô–õ
"""Retry decorators for external API calls"""

import logging
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log
)
from anthropic import APIError, RateLimitError
from postgrest.exceptions import APIError as PostgrestAPIError

logger = logging.getLogger(__name__)

# Retry –¥–ª—è Supabase
db_retry = retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((
        PostgrestAPIError,
        ConnectionError,
        TimeoutError,
    )),
    before_sleep=before_sleep_log(logger, logging.WARNING),
    reraise=True
)

# Retry –¥–ª—è Claude API
ai_retry = retry(
    stop=stop_after_attempt(2),  # API calls –¥–æ—Ä–æ–∂–µ, –º–µ–Ω—å—à–µ –ø–æ–ø—ã—Ç–æ–∫
    wait=wait_exponential(multiplier=2, min=2, max=20),
    retry=retry_if_exception_type((
        RateLimitError,
        APIError,
        TimeoutError,
    )),
    before_sleep=before_sleep_log(logger, logging.WARNING),
    reraise=True
)
```

**3. –ü—Ä–∏–º–µ–Ω–∏ –∫ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º –º–µ—Ç–æ–¥–∞–º –≤ `services/db_service.py`:**

```python
# services/db_service.py - –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from utils.retry import db_retry

class DBService:
    # ... existing __init__ ...

    @db_retry
    def save_message(self, chat_id: int, user_id: int, username: str, message_text: str):
        """Save message with retry logic"""
        # ... existing code ...

    @db_retry
    def get_subscription(self, user_id: int):
        """Get subscription with retry logic"""
        # ... existing code ...

    @db_retry
    def create_subscription(self, user_id: int, tier: str, ...):
        """Create subscription with retry logic"""
        # ... existing code ...

    # –î–æ–±–∞–≤—å @db_retry –∫–æ –í–°–ï–ú –º–µ—Ç–æ–¥–∞–º –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç DB calls
```

**4. –ü—Ä–∏–º–µ–Ω–∏ –∫ AI calls –≤ `services/ai_service.py`:**

```python
# services/ai_service.py - –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from utils.retry import ai_retry

class AIService:
    # ... existing __init__ ...

    @ai_retry
    def generate_summary(self, messages: list, personality: dict, ...):
        """Generate summary with retry logic"""
        # ... existing code ...

    @ai_retry
    def generate_chat_response(self, personality: dict, history: list, ...):
        """Generate chat response with retry logic"""
        # ... existing code ...

    @ai_retry
    def generate_judge_verdict(self, ...):
        """Generate verdict with retry logic"""
        # ... existing code ...
```

**5. –î–æ–±–∞–≤—å timeout –∫ HTTP clients:**

```python
# services/db_service.py - –≤ __init__
from supabase import create_client, Client
from supabase.lib.client_options import ClientOptions
import httpx

def __init__(self):
    # –î–æ–±–∞–≤—å timeout
    self.client: Client = create_client(
        config.SUPABASE_URL,
        config.SUPABASE_KEY,
        options=ClientOptions(
            headers={"Connection": "keep-alive"},
            timeout=10.0  # 10 —Å–µ–∫—É–Ω–¥ timeout
        )
    )

# services/ai_service.py - –≤ __init__
import anthropic

def __init__(self):
    self.client = anthropic.Anthropic(
        api_key=config.ANTHROPIC_API_KEY,
        timeout=30.0,  # 30 —Å–µ–∫—É–Ω–¥ –¥–ª—è AI (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–≥–æ)
        max_retries=0,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–æ–π retry –º–µ—Ö–∞–Ω–∏–∑–º
    )
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/integration/test_retry_logic.py`

```python
import pytest
from unittest.mock import patch, Mock
from services.db_service import DBService
from services.ai_service import AIService
from postgrest.exceptions import APIError
from anthropic import RateLimitError

def test_db_retry_on_network_error():
    """Test that DB operations retry on network errors"""
    db = DBService()

    # Mock client to fail 2 times, then succeed
    call_count = [0]

    def failing_insert(*args, **kwargs):
        call_count[0] += 1
        if call_count[0] < 3:
            raise ConnectionError("Network timeout")
        return Mock(data=[{'id': 1}])

    with patch.object(db.client.table('messages'), 'insert', side_effect=failing_insert):
        # Should succeed after retries
        db.save_message(123, 456, 'user', 'test message')

    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å 3 –ø–æ–ø—ã—Ç–∫–∏
    assert call_count[0] == 3, f"Expected 3 attempts, got {call_count[0]}"

def test_db_fails_after_max_retries():
    """Test that DB operations fail after max retries"""
    db = DBService()

    # Mock client to always fail
    with patch.object(
        db.client.table('messages'),
        'insert',
        side_effect=ConnectionError("Network timeout")
    ):
        # Should raise after 3 attempts
        with pytest.raises(ConnectionError):
            db.save_message(123, 456, 'user', 'test message')

def test_ai_retry_on_rate_limit():
    """Test that AI operations retry on rate limit"""
    ai = AIService()

    call_count = [0]

    def rate_limited_call(*args, **kwargs):
        call_count[0] += 1
        if call_count[0] < 2:
            raise RateLimitError("Rate limit exceeded", response=Mock(), body={})
        return Mock(content=[Mock(text="Summary")])

    with patch.object(ai.client.messages, 'create', side_effect=rate_limited_call):
        result = ai.generate_summary([], {'system_prompt': 'test'}, {})

    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å 2 –ø–æ–ø—ã—Ç–∫–∏
    assert call_count[0] == 2

def test_retry_exponential_backoff():
    """Test that retry uses exponential backoff"""
    import time
    db = DBService()

    call_times = []

    def failing_insert(*args, **kwargs):
        call_times.append(time.time())
        if len(call_times) < 3:
            raise ConnectionError("Timeout")
        return Mock(data=[{'id': 1}])

    with patch.object(db.client.table('messages'), 'insert', side_effect=failing_insert):
        db.save_message(123, 456, 'user', 'test')

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã —Ä–∞—Å—Ç—É—Ç —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ
    if len(call_times) >= 3:
        interval1 = call_times[1] - call_times[0]
        interval2 = call_times[2] - call_times[1]

        # –í—Ç–æ—Ä–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ –ø–µ—Ä–≤–æ–≥–æ
        assert interval2 > interval1, "Backoff should be exponential"
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –£—Å—Ç–∞–Ω–æ–≤–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip install tenacity==8.2.3

# 2. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/integration/test_retry_logic.py -v

# 3. –ü—Ä–æ–≤–µ—Ä—å —á—Ç–æ retry —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ production
# –í—Ä–µ–º–µ–Ω–Ω–æ —Å–¥–µ–ª–∞–π DB unavailable (–æ—Ç–∫–ª—é—á–∏ Supabase –≤ dashboard –Ω–∞ 10 —Å–µ–∫)
# –û—Ç–ø—Ä–∞–≤—å –∫–æ–º–∞–Ω–¥—É –±–æ—Ç—É - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å retry –ø–æ–ø—ã—Ç–∫–∞ –≤ –ª–æ–≥–∞—Ö

# 4. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ - –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ø–∏—Å–∏ "Retrying..."
# Vercel Dashboard ‚Üí Logs ‚Üí Search "Retrying"
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] `tenacity` –¥–æ–±–∞–≤–ª–µ–Ω –≤ requirements
- [ ] `utils/retry.py` —Å–æ–∑–¥–∞–Ω
- [ ] `@db_retry` –¥–æ–±–∞–≤–ª–µ–Ω –∫–æ –≤—Å–µ–º DB –º–µ—Ç–æ–¥–∞–º
- [ ] `@ai_retry` –¥–æ–±–∞–≤–ª–µ–Ω –∫–æ –≤—Å–µ–º AI –º–µ—Ç–æ–¥–∞–º
- [ ] Timeouts —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –Ω–∞ HTTP clients
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Retry —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏ network errors
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: add retry logic for DB and AI calls"`

---

### –®–ê–ì 10: Connection Pooling –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üî¥ –ö–†–ò–¢–ò–ß–ù–û
**–†–∏—Å–∫:** Resource leak, –º–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
**–§–∞–π–ª—ã:** `services/db_service.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# services/db_service.py:17-22
class DBService:
    def __init__(self):
        self.client = create_client(...)  # –ù–æ–≤—ã–π client –ø—Ä–∏ –∫–∞–∂–¥–æ–º DBService()
```

–ü—Ä–∏ –∫–∞–∂–¥–æ–º `DBService()` —Å–æ–∑–¥–∞—ë—Ç—Å—è –Ω–æ–≤—ã–π Supabase client:
- –ù–æ–≤–æ–µ TCP connection
- –ù–æ–≤–∞—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
- Memory leak (—Å—Ç–∞—Ä—ã–µ connections –Ω–µ –∑–∞–∫—Ä—ã–≤–∞—é—Ç—Å—è)

**–í serverless —ç—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –∫—Ä–∏—Ç–∏—á–Ω–æ** - –∫–∞–∂–¥—ã–π webhook —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–π client.

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –°–æ–∑–¥–∞–π singleton –¥–ª—è Supabase client –≤ `services/db_service.py`:**

```python
# services/db_service.py - –í –ù–ê–ß–ê–õ–ï –§–ê–ô–õ–ê, –î–û –∫–ª–∞—Å—Å–∞ DBService

import logging
from supabase import create_client, Client
from supabase.lib.client_options import ClientOptions
import config

logger = logging.getLogger(__name__)

# ===== SINGLETON SUPABASE CLIENT =====
_supabase_client: Client = None

def get_supabase_client() -> Client:
    """
    Get or create Supabase client (Singleton pattern)

    In serverless, this keeps connection alive between requests
    in the same worker instance.
    """
    global _supabase_client

    if _supabase_client is None:
        logger.info("Creating new Supabase client (singleton)")
        _supabase_client = create_client(
            config.SUPABASE_URL,
            config.SUPABASE_KEY,
            options=ClientOptions(
                headers={
                    "Connection": "keep-alive",
                    "Keep-Alive": "timeout=30, max=100"
                },
                timeout=10.0
            )
        )

    return _supabase_client

# ===== END SINGLETON =====


class DBService:
    """Database service with connection pooling"""

    def __init__(self):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º singleton –≤–º–µ—Å—Ç–æ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ client
        self.client = get_supabase_client()

    # ... rest of existing methods ...
```

**2. –î–æ–±–∞–≤—å connection health check (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**

```python
# services/db_service.py - –ø–æ—Å–ª–µ get_supabase_client()

def health_check_supabase() -> bool:
    """Check if Supabase connection is healthy"""
    try:
        client = get_supabase_client()
        # –ü—Ä–æ—Å—Ç–æ–π query –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        result = client.table('personalities').select('id').limit(1).execute()
        return result is not None
    except Exception as e:
        logger.error(f"Supabase health check failed: {e}")
        return False
```

**3. –î–æ–±–∞–≤—å cleanup –ø—Ä–∏ graceful shutdown (–¥–ª—è non-serverless):**

```python
# services/db_service.py - –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞

import atexit

def cleanup_supabase_client():
    """Cleanup Supabase client on shutdown"""
    global _supabase_client
    if _supabase_client is not None:
        logger.info("Cleaning up Supabase client")
        # Supabase client doesn't have explicit close(), –Ω–æ –º–æ–∂–µ–º –æ–±–Ω—É–ª–∏—Ç—å
        _supabase_client = None

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º cleanup
atexit.register(cleanup_supabase_client)
```

**4. –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ –¥–ª—è AI service (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):**

```python
# services/ai_service.py - —Å–¥–µ–ª–∞–π —Ç–æ –∂–µ —Å–∞–º–æ–µ

_anthropic_client = None

def get_anthropic_client():
    """Get or create Anthropic client (Singleton)"""
    global _anthropic_client

    if _anthropic_client is None:
        logger.info("Creating new Anthropic client (singleton)")
        _anthropic_client = anthropic.Anthropic(
            api_key=config.ANTHROPIC_API_KEY,
            timeout=30.0,
            max_retries=0
        )

    return _anthropic_client


class AIService:
    def __init__(self):
        self.client = get_anthropic_client()
        self.model = config.ANTHROPIC_MODEL
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/unit/test_connection_pooling.py`

```python
import pytest
from services.db_service import DBService, get_supabase_client, _supabase_client

def test_supabase_client_is_singleton():
    """Test that Supabase client is reused (singleton)"""
    # –ü–µ—Ä–≤—ã–π –≤—ã–∑–æ–≤
    client1 = get_supabase_client()

    # –í—Ç–æ—Ä–æ–π –≤—ã–∑–æ–≤
    client2 = get_supabase_client()

    # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –û–î–ò–ù –ò –¢–û–¢ –ñ–ï –æ–±—ä–µ–∫—Ç
    assert client1 is client2, "Supabase client should be singleton!"

def test_db_service_reuses_client():
    """Test that multiple DBService instances share client"""
    db1 = DBService()
    db2 = DBService()

    # –û–±–∞ –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ client
    assert db1.client is db2.client, "DBService instances should share client!"

def test_connection_pooling_performance():
    """Test that connection pooling improves performance"""
    import time

    # –ü–µ—Ä–≤–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ (cold start)
    start1 = time.time()
    db1 = DBService()
    time1 = time.time() - start1

    # –í—Ç–æ—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±—ã—Å—Ç—Ä–µ–µ)
    start2 = time.time()
    db2 = DBService()
    time2 = time.time() - start2

    # –í—Ç–æ—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–û –±—ã—Å—Ç—Ä–µ–µ
    assert time2 < time1 / 2, \
        f"Connection pooling should be faster! time1={time1:.4f}, time2={time2:.4f}"

def test_health_check():
    """Test Supabase health check"""
    from services.db_service import health_check_supabase

    is_healthy = health_check_supabase()

    assert is_healthy is True, "Supabase should be healthy"

@pytest.mark.benchmark
def test_connection_pooling_under_load(benchmark):
    """Benchmark: connection pooling vs new connections"""

    def create_db_service():
        db = DBService()
        # Simulate query
        return db

    # Benchmark –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –≤—ã–∑–æ–≤—ã –±—ã—Å—Ç—Ä–µ–µ
    result = benchmark(create_db_service)
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/unit/test_connection_pooling.py -v

# 2. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ - –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –û–î–ù–û —Å–æ–æ–±—â–µ–Ω–∏–µ "Creating new Supabase client"
# –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∫–æ–º–∞–Ω–¥

# 3. Benchmark (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
pip install pytest-benchmark
pytest tests/unit/test_connection_pooling.py::test_connection_pooling_under_load --benchmark-only

# 4. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ connections –≤ Supabase
# Supabase Dashboard ‚Üí Settings ‚Üí Database ‚Üí Connection pooling
# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–Ω—å—à–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö connections –ø–æ—Å–ª–µ —Ñ–∏–∫—Å–∞
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] Singleton pattern —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
- [ ] `get_supabase_client()` —Ñ—É–Ω–∫—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞
- [ ] `DBService` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç singleton
- [ ] Health check –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] –í –ª–æ–≥–∞—Ö —Ç–æ–ª—å–∫–æ –û–î–ù–û "Creating new Supabase client"
- [ ] Performance —É–ª—É—á—à–µ–Ω (benchmark)
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "fix: implement connection pooling for Supabase"`

---

## üü† –í–ê–ñ–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ (–í –¢–ï–ß–ï–ù–ò–ï –ù–ï–î–ï–õ–ò)

### –®–ê–ì 11: Auto-cleanup –ø—Ä–∏ –∫–∞–∂–¥–æ–º save_message

**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** üü† –í–ê–ñ–ù–û
**–†–∏—Å–∫:** Performance degradation
**–§–∞–π–ª—ã:** `services/db_service.py`

#### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:
```python
# services/db_service.py:46-54
def save_message(self, ...):
    # Save message
    ...
    # Auto-cleanup OLD messages - –ö–ê–ñ–î–´–ô –†–ê–ó!
    self._cleanup_old_messages(chat_id)
```

Cleanup –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø—Ä–∏ **–ö–ê–ñ–î–û–ú** —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è:
- DELETE query –ø—Ä–∏ –∫–∞–∂–¥–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
- –õ–∏—à–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ –ë–î
- –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞ webhook

#### –ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:

**1. –ó–∞–º–µ–Ω–∏ auto-cleanup –Ω–∞ probabilistic cleanup:**

```python
# services/db_service.py - –≤ save_message()

import random

def save_message(self, chat_id: int, user_id: int, username: str, message_text: str):
    """Save message to database with probabilistic cleanup"""

    # ... existing save code ...

    # ===== –ë–´–õ–û (–ú–ï–î–õ–ï–ù–ù–û): =====
    # self._cleanup_old_messages(chat_id)

    # ===== –°–¢–ê–õ–û (–ë–´–°–¢–†–û): =====
    # Cleanup —Ç–æ–ª—å–∫–æ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 1% (1 –∏–∑ 100 —Å–æ–æ–±—â–µ–Ω–∏–π)
    if random.random() < 0.01:
        logger.debug(f"Running probabilistic cleanup for chat {chat_id}")
        self._cleanup_old_messages(chat_id)
    # ===== END =====
```

**2. –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π background task (–¥–ª—è non-serverless):**

```python
# services/db_service.py - –¥–æ–±–∞–≤—å –º–µ—Ç–æ–¥

import threading
from datetime import datetime, timedelta

_last_cleanup = {}  # {chat_id: datetime}
_cleanup_lock = threading.Lock()

def save_message(self, chat_id: int, user_id: int, username: str, message_text: str):
    """Save message with background cleanup"""

    # ... existing save code ...

    # Cleanup –Ω–µ —á–∞—â–µ 1 —Ä–∞–∑–∞ –≤ —á–∞—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞—Ç–∞
    with _cleanup_lock:
        last = _last_cleanup.get(chat_id)
        should_cleanup = (
            last is None or
            (datetime.now() - last) > timedelta(hours=1)
        )

        if should_cleanup:
            _last_cleanup[chat_id] = datetime.now()

            # –ó–∞–ø—É—Å–∫–∞–µ–º cleanup –≤ —Ñ–æ–Ω–µ (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç webhook)
            thread = threading.Thread(
                target=self._cleanup_old_messages,
                args=(chat_id,),
                daemon=True
            )
            thread.start()
```

**3. –î–æ–±–∞–≤—å manual cleanup command (–¥–ª—è –∞–¥–º–∏–Ω–æ–≤):**

```python
# modules/admin.py - –¥–æ–±–∞–≤—å –∫–æ–º–∞–Ω–¥—É

async def cleanup_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Manual cleanup old messages (admin only)"""
    user_id = update.effective_user.id

    if user_id not in config.ADMIN_USER_IDS:
        await update.message.reply_text("‚ùå Admin only")
        return

    db = DBService()

    # Cleanup all chats
    await update.message.reply_text("üîÑ Starting cleanup...")

    # Get all chats
    chats = db.client.table('chat_metadata').select('chat_id').execute()

    cleaned = 0
    for chat in chats.data:
        deleted = db._cleanup_old_messages(chat['chat_id'])
        cleaned += deleted

    await update.message.reply_text(
        f"‚úÖ Cleanup complete!\n"
        f"Deleted {cleaned} old messages from {len(chats.data)} chats"
    )

# –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è:
# application.add_handler(CommandHandler('cleanup', cleanup_command))
```

#### –¢–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `tests/unit/test_cleanup_performance.py`

```python
import pytest
import time
from services.db_service import DBService
from unittest.mock import patch

def test_cleanup_not_called_every_time():
    """Test that cleanup is not called for every message"""
    db = DBService()

    cleanup_calls = [0]

    def mock_cleanup(chat_id):
        cleanup_calls[0] += 1

    with patch.object(db, '_cleanup_old_messages', side_effect=mock_cleanup):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º 100 —Å–æ–æ–±—â–µ–Ω–∏–π
        for i in range(100):
            db.save_message(123, 456, 'user', f'message {i}')

    # Cleanup –¥–æ–ª–∂–µ–Ω –≤—ã–∑–≤–∞—Ç—å—Å—è ~1 —Ä–∞–∑ (probabilistic 1%)
    assert cleanup_calls[0] <= 5, \
        f"Cleanup called {cleanup_calls[0]} times, expected ~1-2"

def test_save_message_performance_without_cleanup():
    """Test that save_message is fast without cleanup"""
    db = DBService()

    # Mock cleanup to do nothing
    with patch.object(db, '_cleanup_old_messages', return_value=0):
        start = time.time()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º 10 —Å–æ–æ–±—â–µ–Ω–∏–π
        for i in range(10):
            db.save_message(123, 456, 'user', f'test {i}')

        elapsed = time.time() - start

    # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –±—ã—Å—Ç—Ä–æ (<1 —Å–µ–∫—É–Ω–¥–∞ –¥–ª—è 10 —Å–æ–æ–±—â–µ–Ω–∏–π)
    assert elapsed < 1.0, f"save_message too slow: {elapsed:.2f}s"

@pytest.mark.benchmark
def test_cleanup_frequency(benchmark):
    """Benchmark cleanup frequency"""
    db = DBService()

    def save_messages():
        for i in range(100):
            db.save_message(999, 111, 'user', f'msg {i}')

    # Benchmark –¥–æ–ª–∂–µ–Ω –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ cleanup –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ä–µ–¥–∫–æ
    benchmark(save_messages)
```

#### –ö–∞–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å:
```bash
# 1. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
pytest tests/unit/test_cleanup_performance.py -v

# 2. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ - "Running probabilistic cleanup" –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–¥–∫–æ
# –û—Ç–ø—Ä–∞–≤—å 100 —Å–æ–æ–±—â–µ–Ω–∏–π –±–æ—Ç—É, –ø—Ä–æ–≤–µ—Ä—å —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ cleanup –∑–∞–ø—É—Å—Ç–∏–ª—Å—è

# 3. Benchmark
pytest tests/unit/test_cleanup_performance.py::test_cleanup_frequency --benchmark-only

# 4. –ü—Ä–æ–≤–µ—Ä—å DB performance
# Supabase Dashboard ‚Üí Performance ‚Üí Query Stats
# DELETE queries –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–µ–Ω—å—à–µ –ø–æ—Å–ª–µ —Ñ–∏–∫—Å–∞
```

#### –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
- [ ] Probabilistic cleanup —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω (1% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å)
- [ ] –ò–ª–∏ background cleanup (1 —Ä–∞–∑ –≤ —á–∞—Å)
- [ ] Manual cleanup command –¥–æ–±–∞–≤–ª–µ–Ω
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Performance —É–ª—É—á—à–µ–Ω (–º–µ–Ω—å—à–µ DELETE queries)
- [ ] –ö–æ–º–º–∏—Ç: `git commit -m "perf: optimize message cleanup frequency"`

---

*–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ä–∞–∑–¥–µ–ª–µ...*

---

## üìù –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –†–ï–°–£–†–°–´

### –°–æ–∑–¥–∞–Ω–∏–µ requirements-dev.txt

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `requirements-dev.txt`

```
# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
pytest-benchmark==4.0.0
pytest-mock==3.12.0

# Code quality
flake8==6.1.0
black==23.12.1
mypy==1.7.1
isort==5.13.2

# Security scanning
bandit==1.7.5
safety==2.3.5

# Utilities
ipython==8.18.1
httpx==0.27.2
```

### Pre-commit hooks

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `.pre-commit-config.yaml`

```yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
      - id: check-merge-conflict

  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black
        language_version: python3.11

  - repo: https://github.com/PyCQA/flake8
    rev: 6.1.0
    hooks:
      - id: flake8
        args: ['--max-line-length=100', '--ignore=E203,W503']

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.5
    hooks:
      - id: bandit
        args: ['-ll']
        files: .py$

  - repo: https://github.com/Yelp/detect-secrets
    rev: v1.4.0
    hooks:
      - id: detect-secrets
        args: ['--baseline', '.secrets.baseline']
```

### GitHub Actions CI/CD

**–°–æ–∑–¥–∞–π —Ñ–∞–π–ª:** `.github/workflows/test.yml`

```yaml
name: Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run linters
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          black --check .

      - name: Run security checks
        run: |
          bandit -r . -ll

      - name: Run tests
        env:
          SECRET_KEY: test_secret_key_32_chars_long_!
          TELEGRAM_BOT_TOKEN: test_token
          TELEGRAM_WEBHOOK_SECRET: test_webhook_secret
          ANTHROPIC_API_KEY: test_api_key
          SUPABASE_URL: https://test.supabase.co
          SUPABASE_KEY: test_key
        run: |
          pytest tests/ --cov=. --cov-report=xml --cov-report=html

      - name: Check coverage
        run: |
          coverage=$(pytest --cov=. --cov-report=term | grep TOTAL | awk '{print $4}' | sed 's/%//')
          if [ "${coverage}" -lt 60 ]; then
            echo "Coverage ${coverage}% is below 60%"
            exit 1
          fi

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
```

---

## üéØ –ü–†–û–ì–†–ï–°–° TRACKER

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –±–∞–≥–∏:
- [ ] –®–ê–ì 1: SQL Injection
- [ ] –®–ê–ì 2: –î–µ—Ñ–æ–ª—Ç–Ω—ã–π SECRET_KEY
- [ ] –®–ê–ì 3: Race Condition
- [ ] –®–ê–ì 4: Webhook Verification
- [ ] –®–ê–ì 5: Cache TTL Bug
- [ ] –®–ê–ì 6: YooKassa Async
- [ ] –®–ê–ì 7: Idempotency Check
- [ ] –®–ê–ì 8: Signature Logging
- [ ] –®–ê–ì 9: Retry Logic
- [ ] –®–ê–ì 10: Connection Pooling

### –í–∞–∂–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:
- [ ] –®–ê–ì 11: Cleanup Performance
- [ ] –®–ê–ì 12-18: (–±—É–¥—É—Ç –¥–æ–±–∞–≤–ª–µ–Ω—ã)

---

**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞:** 1.0
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** 2025-11-18
**–°—Ç–∞—Ç—É—Å:** 10 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —à–∞–≥–æ–≤ –≥–æ—Ç–æ–≤—ã

---

## üí¨ –ö–ê–ö –†–ê–ë–û–¢–ê–¢–¨ –° –≠–¢–ò–ú –î–û–ö–£–ú–ï–ù–¢–û–ú

### –í –Ω–æ–≤–æ–º —á–∞—Ç–µ —Å Claude:

```
–ü—Ä–∏–≤–µ—Ç! –Ø —Ä–∞–±–æ—Ç–∞—é –Ω–∞–¥ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –±–∞–≥–æ–≤.
–û—Ç–∫—Ä–æ–π —Ñ–∞–π–ª SECURITY_FIXES.md –∏ —Å–¥–µ–ª–∞–π –®–ê–ì 1.

–°–æ–∑–¥–∞–π –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã:
1. –ü—Ä–∏–º–µ–Ω–∏ —Ñ–∏–∫—Å
2. –°–æ–∑–¥–∞–π —Ç–µ—Å—Ç—ã
3. –ó–∞–ø—É—Å—Ç–∏ —Ç–µ—Å—Ç—ã
4. –°–æ–∑–¥–∞–π –∫–æ–º–º–∏—Ç

–ö–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á–∏—à—å - –æ—Ç–º–µ—Ç—å —á–µ–∫–±–æ–∫—Å ‚úÖ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.
```

Claude –≤—ã–ø–æ–ª–Ω–∏—Ç –≤–µ—Å—å —à–∞–≥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏!
